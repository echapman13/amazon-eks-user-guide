include::../attributes.txt[]

[.topic]
[#hybrid-nodes-add-ons]
= Configure add-ons for hybrid nodes
:info_titleabbrev: Configure add-ons

[abstract]
--
Configure common add-ons for hybrid nodes
--

This page describes considerations for running {aws} add-ons and community add-ons on Amazon EKS Hybrid Nodes. To learn more about Amazon EKS add-ons and the processes for creating, upgrading, and removing add-ons from your cluster, see <<eks-add-ons>>. Unless otherwise noted on this page, the processes for creating, upgrading, and removing Amazon EKS add-ons is the same for Amazon EKS clusters with hybrid nodes as it is for Amazon EKS clusters with nodes running in {aws} Cloud. Only the add-ons included on this page have been validated for compatibility with Amazon EKS Hybrid Nodes.

The following {aws} add-ons are compatible with Amazon EKS Hybrid Nodes.

[cols="1,1", options="header"]
|===
|{aws} add-on
|Compatible add-on versions

|kube-proxy
|v1.25.14-eksbuild.2 and above

|CoreDNS
|v1.9.3-eksbuild.7 and above

|{aws} Distro for OpenTelemetry (ADOT)
|v0.102.1-eksbuild.2 and above

|CloudWatch Observability agent
|v2.2.1-eksbuild.1 and above

|EKS Pod Identity Agent
|v1.3.3-eksbuild.1 and above

|Node monitoring agent
|v1.2.0-eksbuild.1 and above

|CSI snapshot controller
|v8.1.0-eksbuild.1 and above
|===

The following community add-ons are compatible with Amazon EKS Hybrid Nodes. To learn more about community add-ons, see <<community-addons>>.

[cols="1,1", options="header"]
|===
|Community add-on
|Compatible add-on versions

|Kubernetes Metrics Server
|v0.7.2-eksbuild.1 and above
|===

In addition to the Amazon EKS add-ons in the tables above, the <<prometheus,Amazon Managed Service for Prometheus Collector>>, and the <<aws-load-balancer-controller,{aws} Load Balancer Controller>> for <<alb-ingress,application ingress>> (HTTP) and <<network-load-balancing,load balancing>> (TCP/UDP) are compatible with hybrid nodes. 

There are {aws} add-ons and community add-ons that aren't compatible with Amazon EKS Hybrid Nodes. The latest versions of these add-ons have an anti-affinity rule for the default `eks.amazonaws.com/compute-type: hybrid` label applied to hybrid nodes. This prevents them from running on hybrid nodes when deployed in your clusters. If you have clusters with both hybrid nodes and nodes running in {aws} Cloud, you can deploy these add-ons in your cluster to nodes running in {aws} Cloud. The Amazon VPC CNI is not compatible with hybrid nodes, and Cilium and Calico are supported as the Container Networking Interfaces (CNIs) for Amazon EKS Hybrid Nodes. See <<hybrid-nodes-cni>> for more information.

[#hybrid-nodes-add-ons-aws-add-ons]
== {aws} add-ons

The sections that follow describe differences between running compatible {aws} add-ons on hybrid nodes compared to other Amazon EKS compute types.

[#hybrid-nodes-add-ons-core]
== kube-proxy and CoreDNS

EKS installs kube-proxy and CoreDNS as self-managed add-ons by default when you create an EKS cluster with the {aws} API and {aws} SDKs, including from the {aws} CLI. You can overwrite these add-ons with Amazon EKS add-ons after cluster creation. Reference the EKS documentation for details on <<managing-kube-proxy>> and <<managing-coredns>>.  If you are running a mixed mode cluster with both hybrid nodes and nodes in {aws} Cloud, it is recommended to have at least one CoreDNS replica on hybrid nodes and at least one CoreDNS replica on your nodes in {aws} Cloud. See <<hybrid-nodes-mixed-coredns>> for configuration steps.

[#hybrid-nodes-add-ons-cw]
== CloudWatch Observability agent
The CloudWatch Observability agent operator uses https://kubernetes.io/docs/reference/access-authn-authz/webhook/[webhooks]. If you run the operator on hybrid nodes, your on-premises pod CIDR must be routable on your on-premises network and you must configure your EKS cluster with your remote pod network. For more information, see <<hybrid-nodes-webhooks, Configure webhooks for hybrid nodes>>.

Node-level metrics are not available for hybrid nodes because link:AmazonCloudWatch/latest/monitoring/ContainerInsights.html[CloudWatch Container Insights,type="documentation"] depends on the availability of link:AWSEC2/latest/UserGuide/configuring-instance-metadata-service.html[Instance Metadata Service,type="documentation"] (IMDS) for node-level metrics. Cluster, workload, pod, and container-level metrics are available for hybrid nodes.

After installing the add-on by following the steps described in link:AmazonCloudWatch/latest/monitoring/install-CloudWatch-Observability-EKS-addon.html[Install the CloudWatch agent with the Amazon CloudWatch Observability,type="documentation"], the add-on manifest must be updated before the agent can run successfully on hybrid nodes. Edit the `amazoncloudwatchagents` resource on the cluster to add the `RUN_WITH_IRSA` environment variable as shown below.
[source,bash,subs="verbatim,attributes"]
----
kubectl edit amazoncloudwatchagents -n amazon-cloudwatch cloudwatch-agent
----
[source,yaml,subs="verbatim,attributes"]
----
apiVersion: v1
items:
- apiVersion: cloudwatch.aws.amazon.com/v1alpha1
  kind: AmazonCloudWatchAgent
  metadata:
    ...
    name: cloudwatch-agent
    namespace: amazon-cloudwatch
    ...
  spec:
    ...
    env:
    - name: RUN_WITH_IRSA # <-- Add this
      value: "True" # <-- Add this
    - name: K8S_NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
          ...
----

[#hybrid-nodes-add-ons-amp]
== Amazon Managed Prometheus managed collector for hybrid nodes

An Amazon Managed Service for Prometheus (AMP) managed collector consists of a scraper that discovers and collects metrics from the resources in an Amazon EKS cluster. AMP manages the scraper for you, removing the need to manage any instances, agents, or scrapers yourself.

You can use AMP managed collectors without any additional configuration specific to hybrid nodes. However the metric endpoints for your applications on the hybrid nodes must be reachable from the VPC, including routes from the VPC to remote pod network CIDRs and the ports open in your on-premises firewall. Additionally, your cluster must have <<cluster-endpoint,private cluster endpoint access>>.

Follow the steps in link:prometheus/latest/userguide/AMP-collector-how-to.html[Using an {aws} managed collector,type="documentation"] in the Amazon Managed Service for Prometheus User Guide.

[#hybrid-nodes-add-ons-adot]
== {aws} Distro for OpenTelemetry (ADOT)

You can use the {aws} Distro for OpenTelemetry (ADOT) add-on to collect metrics, logs, and tracing data from your applications running on hybrid nodes. ADOT uses admission https://kubernetes.io/docs/reference/access-authn-authz/webhook/[webhooks] to mutate and validate the Collector Custom Resource requests. If you run the ADOT operator on hybrid nodes, your on-premises pod CIDR must be routable on your on-premises network and you must configure your EKS cluster with your remote pod network. For more information, see <<hybrid-nodes-webhooks, Configure webhooks for hybrid nodes>>.

Follow the steps in https://aws-otel.github.io/docs/getting-started/adot-eks-add-on[Getting Started with {aws} Distro for OpenTelemetry using EKS Add-Ons] in the _{aws} Distro for OpenTelemetry_ documentation.

[#hybrid-nodes-add-ons-lbc]
== {aws} Load Balancer Controller

You can use the <<aws-load-balancer-controller,{aws} Load Balancer Controller>> and Application Load Balancer (ALB) or Network Load Balancer (NLB) with the target type ip for workloads on hybrid nodes connected with {aws} Direct Connect or {aws} Site-to-Site VPN. The IP target(s) used with the ALB or NLB must be routable from {aws}. The {aws} Load Balancer controller also uses https://kubernetes.io/docs/reference/access-authn-authz/webhook/[webhooks]. If you run the {aws} Load Balancer Controller operator on hybrid nodes, your on-premises pod CIDR must be routable on your on-premises network and you must configure your EKS cluster with your remote pod network. For more information, see <<hybrid-nodes-webhooks, Configure webhooks for hybrid nodes>>.

To install the {aws} Load Balancer Controller, follow the steps at <<lbc-helm>> or <<lbc-manifest>>.

For ingress with ALB, you must specify the annotations below. See <<alb-ingress>> for instructions.
[source,yaml,subs="verbatim,attributes"]
----
alb.ingress.kubernetes.io/target-type: ip
----

For load balancing with NLB, you must specify the annotations below. See <<network-load-balancing>> for instructions.
[source,yaml,subs="verbatim,attributes"]
----
service.beta.kubernetes.io/aws-load-balancer-type: "external" 
service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: "ip"
----

[#hybrid-nodes-add-ons-pod-id]
== EKS Pod Identity Agent

The original Amazon EKS Pod Identity Agent DaemonSet relies on the availability of EC2 IMDS on the node to obtain the required {aws} credentials. As IMDS isn't available on hybrid nodes, starting in add-on version `1.3.3-eksbuild.1`, the Pod Identity Agent add-on optionally deploys a second DaemonSet that specifically targets hybrid nodes. This DaemonSet mounts the required credentials to the pods created by the Pod Identity Agent add-on.

. To use the Pod Identity agent on hybrid nodes, set `enableCredentialsFile: true` in the hybrid section of `nodeadm` config as shown below:
+
[source,yaml,subs="verbatim,attributes"]
----
apiVersion: node.eks.aws/v1alpha1 
kind: NodeConfig
spec:
    hybrid:
        enableCredentialsFile: true # <-- Add this
----
+
This will configure `nodeadm` to create a credentials file to be configured on the node under `/eks-hybrid/.aws/credentials`, which will be used by `eks-pod-identity-agent` pods. This credentials file will contain temporary {aws} credentials that will be refreshed periodically.
+
. After you update the `nodeadm` config on _each_ node, run the following `nodeadm init` command with your `nodeConfig.yaml` to join your hybrid nodes to your Amazon EKS cluster. If your nodes have joined the cluster previous, still run the `init` command again.
+
[source,bash,subs="verbatim,attributes"]
----
nodeadm init -c file://nodeConfig.yaml
----
+
. Install `eks-pod-identity-agent` with support for hybrid nodes enabled, by either using the {aws} CLI or {aws-management-console}.
+
.. {aws} CLI: From the machine that you're using to administer the cluster, run the following command to install `eks-pod-identity-agent` with support for hybrid nodes enabled. Replace `my-cluster` with the name of your cluster.
+
[source,bash,subs="verbatim,attributes"]
----
aws eks create-addon \
    --cluster-name my-cluster \
    --addon-name eks-pod-identity-agent \
    --configuration-values '{"daemonsets":{"hybrid":{"create": true}}}'
----
+
.. {aws-management-console}: If you are installing the Pod Identity Agent add-on through the {aws} console, add the following to the optional configuration to deploy the daemonset that targets hybrid nodes.
+
[source,yaml,subs="verbatim,attributes"]
----
{"daemonsets":{"hybrid":{"create": true}}}
----

[#hybrid-nodes-add-ons-csi-snapshotter]
== CSI snapshot controller

Starting with version `v8.1.0-eksbuild.2`, the <<csi-snapshot-controller,CSI snapshot controller add-on>> applies a soft anti-affinity rule for hybrid nodes, preferring the controller `deployment` to run on EC2 in the same {aws} Region as the Amazon EKS control plane. Co-locating the `deployment` in the same {aws} Region as the Amazon EKS control plane improves latency. 

[#hybrid-nodes-add-ons-community]
== Community add-ons

The sections that follow describe differences between running compatible community add-ons on hybrid nodes compared to other Amazon EKS compute types.

[#hybrid-nodes-add-ons-metrics-server]
== Kubernetes Metrics Server
The control plane needs to reach Metrics Server's pod IP (or node IP if hostNetwork is enabled). Therefore, unless you run Metrics Server in hostNetwork mode, you must configure a remote pod network when creating your Amazon EKS cluster, and you must make your pod IP addresses routable. Implementing Border Gateway Protocol (BGP) with the CNI is one common way to make your pod IP addresses routable.
